{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"mimikkyu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デフォルトマーカー位置のインプット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_pts\n",
      "[[[  5.   7.]\n",
      "  [ 34.   7.]\n",
      "  [ 34.  36.]\n",
      "  [  5.  36.]]\n",
      "\n",
      " [[365.   7.]\n",
      "  [394.   7.]\n",
      "  [394.  36.]\n",
      "  [365.  36.]]\n",
      "\n",
      " [[  5. 187.]\n",
      "  [ 34. 187.]\n",
      "  [ 34. 216.]\n",
      "  [  5. 216.]]\n",
      "\n",
      " [[365. 187.]\n",
      "  [394. 187.]\n",
      "  [394. 216.]\n",
      "  [365. 216.]]\n",
      "\n",
      " [[185.   7.]\n",
      "  [214.   7.]\n",
      "  [214.  36.]\n",
      "  [185.  36.]]\n",
      "\n",
      " [[365.  97.]\n",
      "  [394.  97.]\n",
      "  [394. 126.]\n",
      "  [365. 126.]]\n",
      "\n",
      " [[185. 187.]\n",
      "  [214. 187.]\n",
      "  [214. 216.]\n",
      "  [185. 216.]]\n",
      "\n",
      " [[  5.  97.]\n",
      "  [ 34.  97.]\n",
      "  [ 34. 126.]\n",
      "  [  5. 126.]]]\n",
      "def_pro_pts\n",
      "[[185.   7.]\n",
      " [214.   7.]\n",
      " [214.  36.]\n",
      " [185.  36.]\n",
      " [365.  97.]\n",
      " [394.  97.]\n",
      " [394. 126.]\n",
      " [365. 126.]\n",
      " [185. 187.]\n",
      " [214. 187.]\n",
      " [214. 216.]\n",
      " [185. 216.]\n",
      " [  5.  97.]\n",
      " [ 34.  97.]\n",
      " [ 34. 126.]\n",
      " [  5. 126.]]\n",
      "def_bord_pts\n",
      "[[  5.   7.]\n",
      " [ 34.   7.]\n",
      " [ 34.  36.]\n",
      " [  5.  36.]\n",
      " [365.   7.]\n",
      " [394.   7.]\n",
      " [394.  36.]\n",
      " [365.  36.]\n",
      " [  5. 187.]\n",
      " [ 34. 187.]\n",
      " [ 34. 216.]\n",
      " [  5. 216.]\n",
      " [365. 187.]\n",
      " [394. 187.]\n",
      " [394. 216.]\n",
      " [365. 216.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "aruco = cv2.aruco\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "dst=cv2.imread( \"./img/\"+\"/md_\"+str(name)+\".png\") \n",
    "def_corners, def_ids, rejectedImgPoints = aruco.detectMarkers(dst, dictionary)\n",
    "\n",
    "count=[0,1,2,3]\n",
    "count2=[0,1,2,3,4,5,6,7]\n",
    "\n",
    "def_pts=np.zeros((8,4,2),dtype = np.float32)\n",
    "\n",
    "for i in count2:\n",
    "    for j in count2:\n",
    "        if j ==def_ids[i][0]:\n",
    "            for k in count:\n",
    "                def_pts[j][k][0]=def_corners[i][0][k][0]\n",
    "                def_pts[j][k][1]=def_corners[i][0][k][1]\n",
    " \n",
    "        \n",
    "height, width, color = dst.shape\n",
    "\n",
    "\n",
    "def_bord_pts=np.zeros((16,2),dtype = np.float32)\n",
    "def_pro_pts=np.zeros((16,2),dtype = np.float32)\n",
    "\n",
    "count=[0,1,2,3]\n",
    "def_pts\n",
    "for i in count:\n",
    "    for j in count:\n",
    "        def_bord_pts[4*i+j][0]=def_pts[i][j][0]\n",
    "        def_bord_pts[4*i+j][1]=def_pts[i][j][1]    \n",
    "\n",
    "for i in count:\n",
    "    for j in count:\n",
    "        def_pro_pts[4*i+j][0]=def_pts[4+i][j][0]\n",
    "        def_pro_pts[4*i+j][1]=def_pts[4+i][j][1]\n",
    "\n",
    "\n",
    "print(\"def_pts\")\n",
    "print(def_pts)\n",
    "print(\"def_pro_pts\")\n",
    "print(def_pro_pts)\n",
    "print(\"def_bord_pts\")\n",
    "print(def_bord_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "貼り付け関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvpaste(img, imgback, x, y, angle, scale):  \n",
    "    # x and y are the distance from the center of the background image \n",
    "\n",
    "    r = img.shape[0]\n",
    "    c = img.shape[1]\n",
    "    rb = imgback.shape[0]\n",
    "    cb = imgback.shape[1]\n",
    "    hrb=round(rb/2)\n",
    "    hcb=round(cb/2)\n",
    "    hr=round(r/2)\n",
    "    hc=round(c/2)\n",
    "\n",
    "    # Copy the forward image and move to the center of the background image\n",
    "    imgrot = np.zeros((rb,cb,3),np.uint8)\n",
    "    imgrot[hrb-hr:hrb+hr,hcb-hc:hcb+hc,:] = img[:hr*2,:hc*2,:]\n",
    "\n",
    "    # Rotation and scaling\n",
    "    M = cv2.getRotationMatrix2D((hcb,hrb),angle,scale)\n",
    "    imgrot = cv2.warpAffine(imgrot,M,(cb,rb))\n",
    "    # Translation\n",
    "    M = np.float32([[1,0,x],[0,1,y]])\n",
    "    imgrot = cv2.warpAffine(imgrot,M,(cb,rb))\n",
    "\n",
    "    # Making mask\n",
    "    imggray = cv2.cvtColor(imgrot,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(imggray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Now black-out the area of the forward image in the background image\n",
    "    img1_bg = cv2.bitwise_and(imgback,imgback,mask = mask_inv)\n",
    "\n",
    "    # Take only region of the forward image.\n",
    "    img2_fg = cv2.bitwise_and(imgrot,imgrot,mask = mask)\n",
    "\n",
    "    # Paste the forward image on the background image\n",
    "    imgpaste = cv2.add(img1_bg,img2_fg)\n",
    "\n",
    "    return imgpaste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロジェクタ起動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "aruco = cv2.aruco\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "img=cv2.imread(\"img/\"+str(name)+\".jpg\")\n",
    "imgback = cv2.imread(\"img/\"+str(name)+\".jpg\")\n",
    "\n",
    "height,width,color=imgback.shape\n",
    "\n",
    "angle=0\n",
    "scale=0.2\n",
    "\n",
    "ar4=cv2.imread(\"ARUCO/blue_ar04.png\")\n",
    "ar5=cv2.imread(\"ARUCO/blue_ar05.png\")\n",
    "ar6=cv2.imread(\"ARUCO/blue_ar06.png\")\n",
    "ar7=cv2.imread(\"ARUCO/blue_ar07.png\")\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "rt_pts=np.zeros((8,4,2),dtype = np.float32)\n",
    "rt_bord_pts=np.zeros((16,2),dtype = np.float32)\n",
    "rt_pro_pts=np.zeros((16,2),dtype = np.float32)\n",
    "\n",
    "count=[0,1,2,3]\n",
    "count2=[0,1,2,3,4,5,6,7]\n",
    "\n",
    "mat1, mask1 = cv2.findHomography(def_pro_pts, def_pro_pts, cv2.RANSAC,1)#初期設定（変更なし）\n",
    "mat2, mask2 = cv2.findHomography(def_bord_pts, def_bord_pts, cv2.RANSAC,1)\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    t0 = time.time()    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    frame2=cv2.warpPerspective(img, mat2, (3*width, 3*height))\n",
    "    frame3=cv2.warpPerspective(frame2, mat1, (width, height))#カメラから見たプロジェクタ上の座標→カメラから見たボード上の座標\n",
    "    \n",
    "\n",
    "    imgpaste = cvpaste(ar4, frame3, 0, -90, angle, scale)\n",
    "    imgpaste2 = cvpaste(ar5, imgpaste, 180, 0, angle, scale)\n",
    "    imgpaste3 = cvpaste(ar6, imgpaste2, 0, 90, angle, scale)\n",
    "    imgpaste4 = cvpaste(ar7, imgpaste3, -180, 0, angle, scale)\n",
    "\n",
    "    \n",
    "    cv2.namedWindow('screen', cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty('screen', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    cv2.imshow('screen',imgpaste4)\n",
    "    \n",
    "    new_corners, new_ids, rejectedImgPoints = aruco.detectMarkers(frame, dictionary)\n",
    "    #print(rt_pro_pts)\n",
    "    #print(rejectedImgPoints)\n",
    "    if not new_corners:\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        num=new_ids.size-1\n",
    "    \n",
    "        if num==7:#全部読み込まれてるならば\n",
    "            for i in count2:\n",
    "                for j in count2:\n",
    "                    if j ==new_ids[i][0]:\n",
    "                        for h in count:\n",
    "                            rt_pts[j][h][0]=new_corners[i][0][h][0]\n",
    "                            rt_pts[j][h][1]=new_corners[i][0][h][1]\n",
    "                if num==i:\n",
    "                    break\n",
    "                    \n",
    "            for i in count:\n",
    "                for j in count:\n",
    "                    rt_bord_pts[4*i+j][0]=rt_pts[i][j][0]\n",
    "                    rt_bord_pts[4*i+j][1]=rt_pts[i][j][1]\n",
    "\n",
    "            for i in count:\n",
    "                for j in count:\n",
    "                    rt_pro_pts[4*i+j][0]=rt_pts[4+i][j][0]\n",
    "                    rt_pro_pts[4*i+j][1]=rt_pts[4+i][j][1]\n",
    "\n",
    "                \n",
    "        \n",
    "            mat1, mask1 = cv2.findHomography(rt_pro_pts, def_pro_pts, cv2.RANSAC,1)\n",
    "            mat2, mask2 = cv2.findHomography(def_bord_pts, rt_bord_pts, cv2.RANSAC,1)\n",
    "    #print(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    " #   print(rt_pro_pts)\n",
    "    if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    t1 = time.time()                # 計測終了時間\n",
    "    elapsed_time = float(t1 - t0)   # 経過時間\n",
    "   # print(elapsed_time)             # 経過時間を表示\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.,   7.],\n",
       "       [ 34.,   7.],\n",
       "       [ 34.,  36.],\n",
       "       [  5.,  36.],\n",
       "       [365.,   7.],\n",
       "       [394.,   7.],\n",
       "       [394.,  36.],\n",
       "       [365.,  36.],\n",
       "       [  5., 187.],\n",
       "       [ 34., 187.],\n",
       "       [ 34., 216.],\n",
       "       [  5., 216.],\n",
       "       [365., 187.],\n",
       "       [394., 187.],\n",
       "       [394., 216.],\n",
       "       [365., 216.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_bord_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[420., 349.],\n",
       "         [481., 355.],\n",
       "         [483., 413.],\n",
       "         [423., 407.]]], dtype=float32),\n",
       " array([[[102., 270.],\n",
       "         [137., 276.],\n",
       "         [135., 316.],\n",
       "         [100., 310.]]], dtype=float32),\n",
       " array([[[ 80.,  89.],\n",
       "         [115.,  85.],\n",
       "         [116., 128.],\n",
       "         [ 80., 132.]]], dtype=float32),\n",
       " array([[[431.,  39.],\n",
       "         [484.,  39.],\n",
       "         [478.,  94.],\n",
       "         [426.,  92.]]], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import datetime\n",
    "img=cv2.imread(\"img/\"+\"/md_\"+str(name)+\".png\")\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while(True):\n",
    "    cv2.namedWindow('screen', cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty('screen', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    cv2.imshow('screen', img)\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "   \n",
    "    k = cv2.waitKey(1)&0xff # キー入力を待つ\n",
    "    if k == ord('p'):\n",
    "        # 「p」キーで画像を保存\n",
    "        date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        path = \"./projector_img/\" + date + \".png\"\n",
    "        cv2.imwrite(path, frame) # ファイル保存\n",
    "\n",
    "        cv2.imshow(path, frame) # キャプチャした画像を表示\n",
    "    elif k == ord('q'):\n",
    "        # 「q」キーが押されたら終了する\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 41., 139.],\n",
       "        [ 80., 138.],\n",
       "        [ 77., 177.],\n",
       "        [ 37., 177.]],\n",
       "\n",
       "       [[516., 125.],\n",
       "        [558., 123.],\n",
       "        [561., 163.],\n",
       "        [519., 164.]],\n",
       "\n",
       "       [[ 23., 373.],\n",
       "        [ 65., 372.],\n",
       "        [ 62., 416.],\n",
       "        [ 20., 417.]],\n",
       "\n",
       "       [[532., 362.],\n",
       "        [576., 362.],\n",
       "        [579., 407.],\n",
       "        [534., 407.]]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "aruco = cv2.aruco\n",
    "\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "image_dir = './projector_img/'\n",
    "search_pattern = '*.png'\n",
    "datas = []\n",
    "for image_path in glob.glob(os.path.join(image_dir,search_pattern)):\n",
    "    # (height,width,channels)\n",
    "    data = cv2.imread(image_path)\n",
    "    # (1,height,width,channels)\n",
    "    data_expanded = np.expand_dims(data,axis=0)\n",
    "    datas.append(data_expanded)\n",
    "# (n_samples,height,width,channels)\n",
    "image_datas = np.concatenate(datas,axis=0)\n",
    "\n",
    "p_img = image_datas[0]\n",
    "pro_corners, pro_ids, rejectedImgPoints = aruco.detectMarkers(p_img, dictionary)\n",
    "pt1=[pro_corners[0][0][0][0],pro_corners[0][0][0][1],pro_ids[0][0]]\n",
    "\n",
    "count=[0,1,2,3]\n",
    "\n",
    "j=pro_ids.size-1\n",
    "\n",
    "rt_pts=np.zeros((4,4,2),dtype = np.float32)\n",
    "\n",
    "for i in count:\n",
    "    for k in count:\n",
    "        if k ==pro_ids[i][0]:\n",
    "            for h in count:\n",
    "                rt_pts[k][h][0]=pro_corners[i][0][h][0]\n",
    "                rt_pts[k][h][1]=pro_corners[i][0][h][1]\n",
    "    if j==i:\n",
    "        break\n",
    "rt_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_EXPOSURE, 40)\n",
    "\n",
    "while(True):\n",
    "   \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "   \n",
    "    k = cv2.waitKey(1)&0xff # キー入力を待つ\n",
    "    if k == ord('p'):\n",
    "        # 「p」キーで画像を保存\n",
    "        date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        path = \"./bord_img/\" + date + \".png\"\n",
    "        cv2.imwrite(path, frame) # ファイル保存\n",
    "\n",
    "        cv2.imshow(path, frame) # キャプチャした画像を表示\n",
    "    elif k == ord('q'):\n",
    "        # 「q」キーが押されたら終了する\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 34., 119.],\n",
       "        [ 79., 121.],\n",
       "        [ 76., 163.],\n",
       "        [ 30., 162.]],\n",
       "\n",
       "       [[538., 129.],\n",
       "        [579., 130.],\n",
       "        [582., 170.],\n",
       "        [540., 170.]],\n",
       "\n",
       "       [[ 15., 379.],\n",
       "        [ 63., 379.],\n",
       "        [ 60., 428.],\n",
       "        [ 10., 429.]],\n",
       "\n",
       "       [[554., 375.],\n",
       "        [597., 374.],\n",
       "        [601., 420.],\n",
       "        [558., 421.]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "aruco = cv2.aruco\n",
    "\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "image_dir = './bord_img/'\n",
    "search_pattern = '*.png'\n",
    "datas = []\n",
    "for image_path in glob.glob(os.path.join(image_dir,search_pattern)):\n",
    "    # (height,width,channels)\n",
    "    data = cv2.imread(image_path)\n",
    "    # (1,height,width,channels)\n",
    "    data_expanded = np.expand_dims(data,axis=0)\n",
    "    datas.append(data_expanded)\n",
    "# (n_samples,height,width,channels)\n",
    "image_datas = np.concatenate(datas,axis=0)\n",
    "\n",
    "b_img = image_datas[0]\n",
    "bor_corners, bor_ids, rejectedImgPoints = aruco.detectMarkers(b_img, dictionary)\n",
    "\n",
    "j=bor_ids.size-1\n",
    "count=[0,1,2,3]\n",
    "\n",
    "rt_pts2=np.zeros((4,4,2),dtype = np.float32)\n",
    "\n",
    "for i in count:\n",
    "    for k in count:\n",
    "        if k ==bor_ids[i][0]:\n",
    "            for h in count:\n",
    "                rt_pts2[k][h][0]=bor_corners[i][0][h][0]\n",
    "                rt_pts2[k][h][1]=bor_corners[i][0][h][1]\n",
    "    if j==i:\n",
    "        break\n",
    "rt_pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def_det_pts=np.zeros((16,2),dtype = np.float32)\n",
    "rt_det_pts=np.zeros((16,2),dtype = np.float32)\n",
    "rt_det_pts2=np.zeros((16,2),dtype = np.float32)\n",
    "\n",
    "count=[0,1,2,3]\n",
    "k=0\n",
    "for i in count:\n",
    "    if rt_pts[i][0][0]==rt_pts[i][0][1]==0 or rt_pts2[i][0][0]==rt_pts2[i][0][1]==0:\n",
    "        print(str(i)+\"番のARは検出できませんでした\")\n",
    "        for j in count2:    \n",
    "            def_det_pts=np.delete(def_det_pts,-1,0)\n",
    "            rt_det_pts=np.delete(rt_det_pts,-1,0)\n",
    "            rt_det_pts2=np.delete(rt_det_pts2,-1,0)\n",
    "    \n",
    "    else:\n",
    "        for j in count:\n",
    "            def_det_pts[4*k+j][0]=def_pts[i][j][0]\n",
    "            def_det_pts[4*k+j][1]=def_pts[i][j][1]\n",
    "        \n",
    "            rt_det_pts[4*k+j][0]=rt_pts[i][j][0]\n",
    "            rt_det_pts[4*k+j][1]=rt_pts[i][j][1]\n",
    "\n",
    "            rt_det_pts2[4*k+j][0]=rt_pts2[i][j][0]\n",
    "            rt_det_pts2[4*k+j][1]=rt_pts2[i][j][1]\n",
    "   \n",
    "        k=k+1  \n",
    "\n",
    "mat1, mask1 = cv2.findHomography(rt_det_pts2,def_det_pts, cv2.RANSAC,1)#カメラ座標からボード座標への変換\n",
    "img2=cv2.warpPerspective(p_img, mat1, (width, height))#ボード座標系におけるプロジェクタ投影画像の座標\n",
    "img2_corners, img2_ids, rejectedImgPoints = aruco.detectMarkers(img2, dictionary)\n",
    "\n",
    "j=img2_ids.size-1\n",
    "count=[0,1,2,3]\n",
    "\n",
    "img2_pts=np.zeros((4,4,2),dtype = np.float32)\n",
    "\n",
    "for i in count:\n",
    "    for k in count:\n",
    "        if k ==img2_ids[i][0]:\n",
    "            for h in count:\n",
    "                img2_pts[k][h][0]=img2_corners[i][0][h][0]\n",
    "                img2_pts[k][h][1]=img2_corners[i][0][h][1]\n",
    "    if j==i:\n",
    "        break\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像確認（ボード座標系に変換した投影画像）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    cv2.imshow('frame', img2)\n",
    "    k = cv2.waitKey(1)&0xff # キー入力を待つ\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロジェクタ位置変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "aruco = cv2.aruco\n",
    "\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "# 画像ファイルのパス\n",
    "or_img=cv2.imread(\"img/\"+str(name)+\".jpg\")\n",
    "h,w,c=or_img.shape\n",
    "frame1 = cv2.imread(\"img/\"+str(name)+\".jpg\")\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "#cap.set(cv2.CAP_PROP_EXPOSURE, 400)\n",
    "while(True):\n",
    "   \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    k = cv2.waitKey(1)&0xff # キー入力を待つ\n",
    "    if k == ord('p'):\n",
    "        # 「p」キーで画像を保存\n",
    "        path = \"./rt_img/realtime.png\"\n",
    "        cv2.imwrite(path, frame) # ファイル保存\n",
    "        cv2.imshow(path, frame) # キャプチャした画像を表示\n",
    "    elif k == ord('q'):\n",
    "        # 「q」キーが押されたら終了する\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新しいボード座標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_img = cv2.imread(\"rt_img/realtime.png\")\n",
    "new_corners, new_ids, rejectedImgPoints = aruco.detectMarkers(rt_img, dictionary)\n",
    "\n",
    "j=new_ids.size-1\n",
    "count=[0,1,2,3]\n",
    "\n",
    "rt_pts3=np.zeros((4,4,2),dtype = np.float32)\n",
    "\n",
    "for i in count:\n",
    "    for k in count:\n",
    "        if k ==new_ids[i][0]:\n",
    "            for h in count:\n",
    "                rt_pts3[k][h][0]=new_corners[i][0][h][0]\n",
    "                rt_pts3[k][h][1]=new_corners[i][0][h][1]\n",
    "    if j==i:\n",
    "        break\n",
    "    \n",
    "def_det_pts=np.zeros((16,2),dtype = np.float32)\n",
    "rt_det_pts3=np.zeros((16,2),dtype = np.float32)\n",
    "rt_det_pts2=np.zeros((16,2),dtype = np.float32)\n",
    "rt_det_pts=np.zeros((16,2),dtype = np.float32)\n",
    "img2_det_pts=np.zeros((16,2),dtype = np.float32)#Pb\n",
    "\n",
    "\n",
    "count=[0,1,2,3]\n",
    "k=0\n",
    "for i in count:\n",
    "    if rt_pts3[i][0][0]==rt_pts3[i][0][1]==0 or rt_pts2[i][0][0]==rt_pts2[i][0][1]==0 or img2_pts[i][0][0]==img2_pts[i][0][1]==0 or rt_pts[i][0][0]==rt_pts[i][0][1]==0:\n",
    "        print(str(i)+\"番のARは検出できませんでした\")\n",
    "        for j in count:    \n",
    "            def_det_pts=np.delete(def_det_pts,-1,0)\n",
    "            rt_det_pts=np.delete(rt_det_pts,-1,0)\n",
    "            rt_det_pts2=np.delete(rt_det_pts2,-1,0)\n",
    "            rt_det_pts3=np.delete(rt_det_pts3,-1,0)\n",
    "            img2_det_pts=np.delete(img2_det_pts,-1,0)\n",
    "    \n",
    "    else:\n",
    "        for j in count:\n",
    "            def_det_pts[4*k+j][0]=def_pts[i][j][0]\n",
    "            def_det_pts[4*k+j][1]=def_pts[i][j][1]\n",
    "        \n",
    "            rt_det_pts3[4*k+j][0]=rt_pts3[i][j][0]\n",
    "            rt_det_pts3[4*k+j][1]=rt_pts3[i][j][1]\n",
    "\n",
    "            rt_det_pts2[4*k+j][0]=rt_pts2[i][j][0]\n",
    "            rt_det_pts2[4*k+j][1]=rt_pts2[i][j][1]\n",
    "            \n",
    "            rt_det_pts[4*k+j][0]=rt_pts[i][j][0]\n",
    "            rt_det_pts[4*k+j][1]=rt_pts[i][j][1]\n",
    "\n",
    "            img2_det_pts[4*k+j][0]=img2_pts[i][j][0]\n",
    "            img2_det_pts[4*k+j][1]=img2_pts[i][j][1]\n",
    "   \n",
    "        k=k+1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変換行列生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2, mask2 = cv2.findHomography(img2_det_pts, def_det_pts, cv2.RANSAC,1)#Hp\n",
    "mat3, mask3 = cv2.findHomography(rt_det_pts, img2_det_pts, cv2.RANSAC,1)#Hc-1\n",
    "mat4, mask4 = cv2.findHomography(def_det_pts, rt_det_pts3, cv2.RANSAC,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "or_img=cv2.imread(\"img/\"+str(name)+\".jpg\")\n",
    "height,width,color=or_img.shape\n",
    "\n",
    "while(True):\n",
    "\n",
    "    frame2=cv2.warpPerspective(or_img, mat4, (width*2, height*2))#\n",
    "    frame3=cv2.warpPerspective(frame2, mat2 ,(width*2, height*2))\n",
    "    frame4=cv2.warpPerspective(frame3, mat3 ,(width, height))\n",
    "   \n",
    "   \n",
    "    cv2.namedWindow('screen', cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty('screen', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    cv2.imshow('screen',frame4)\n",
    "        \n",
    "    if cv2.waitKey(10) &0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "  \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.,  14.],\n",
       "       [ 43.,  14.],\n",
       "       [ 43.,  43.],\n",
       "       [ 14.,  43.],\n",
       "       [356.,  14.],\n",
       "       [385.,  14.],\n",
       "       [385.,  43.],\n",
       "       [356.,  43.],\n",
       "       [356., 181.],\n",
       "       [385., 181.],\n",
       "       [385., 210.],\n",
       "       [356., 210.]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_det_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rt_det_pts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9fc0339a3ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrt_det_pts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rt_det_pts' is not defined"
     ]
    }
   ],
   "source": [
    "rt_det_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34., 119.],\n",
       "       [ 79., 121.],\n",
       "       [ 76., 163.],\n",
       "       [ 30., 162.],\n",
       "       [ 15., 379.],\n",
       "       [ 63., 379.],\n",
       "       [ 60., 428.],\n",
       "       [ 10., 429.]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_det_pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 19.,  28.],\n",
       "       [ 44.,  26.],\n",
       "       [ 45.,  52.],\n",
       "       [ 20.,  54.],\n",
       "       [ 19., 177.],\n",
       "       [ 44., 177.],\n",
       "       [ 44., 203.],\n",
       "       [ 19., 203.]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2_det_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_opencv)",
   "language": "python",
   "name": "conda_opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
