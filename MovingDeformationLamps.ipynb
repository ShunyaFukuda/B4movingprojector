{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対象設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"mimikkyu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デフォルトマーカー位置設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "aruco = cv2.aruco\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "dst=cv2.imread( \"./img/\"+\"/md_\"+str(name)+\".png\") \n",
    "def_corners, def_ids, rejectedImgPoints = aruco.detectMarkers(dst, dictionary)\n",
    "\n",
    "count=[0,1,2,3]\n",
    "count2=[0,1,2,3,4,5,6,7]\n",
    "\n",
    "def_pts=np.zeros((8,4,2),dtype = np.float32)\n",
    "\n",
    "for i in count2:\n",
    "    for j in count2:\n",
    "        if j ==def_ids[i][0]:\n",
    "            for k in count:\n",
    "                def_pts[j][k][0]=def_corners[i][0][k][0]\n",
    "                def_pts[j][k][1]=def_corners[i][0][k][1]\n",
    " \n",
    "        \n",
    "height, width, color = dst.shape\n",
    "\n",
    "\n",
    "def_bord_pts=np.zeros((16,2),dtype = np.float32)\n",
    "def_pro_pts=np.zeros((16,2),dtype = np.float32)\n",
    "\n",
    "count=[0,1,2,3]\n",
    "def_pts\n",
    "for i in count:\n",
    "    for j in count:\n",
    "        def_bord_pts[4*i+j][0]=def_pts[i][j][0]\n",
    "        def_bord_pts[4*i+j][1]=def_pts[i][j][1]    \n",
    "\n",
    "for i in count:\n",
    "    for j in count:\n",
    "        def_pro_pts[4*i+j][0]=def_pts[4+i][j][0]\n",
    "        def_pro_pts[4*i+j][1]=def_pts[4+i][j][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "貼り付け関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvpaste(img, imgback, x, y, angle, scale):  \n",
    "    # x and y are the distance from the center of the background image \n",
    "\n",
    "    r = img.shape[0]\n",
    "    c = img.shape[1]\n",
    "    rb = imgback.shape[0]\n",
    "    cb = imgback.shape[1]\n",
    "    hrb=round(rb/2)\n",
    "    hcb=round(cb/2)\n",
    "    hr=round(r/2)\n",
    "    hc=round(c/2)\n",
    "\n",
    "    # Copy the forward image and move to the center of the background image\n",
    "    imgrot = np.zeros((rb,cb,3),np.uint8)\n",
    "    imgrot[hrb-hr:hrb+hr,hcb-hc:hcb+hc,:] = img[:hr*2,:hc*2,:]\n",
    "\n",
    "    # Rotation and scaling\n",
    "    M = cv2.getRotationMatrix2D((hcb,hrb),angle,scale)\n",
    "    imgrot = cv2.warpAffine(imgrot,M,(cb,rb))\n",
    "    # Translation\n",
    "    M = np.float32([[1,0,x],[0,1,y]])\n",
    "    imgrot = cv2.warpAffine(imgrot,M,(cb,rb))\n",
    "\n",
    "    # Making mask\n",
    "    imggray = cv2.cvtColor(imgrot,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(imggray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Now black-out the area of the forward image in the background image\n",
    "    img1_bg = cv2.bitwise_and(imgback,imgback,mask = mask_inv)\n",
    "\n",
    "    # Take only region of the forward image.\n",
    "    img2_fg = cv2.bitwise_and(imgrot,imgrot,mask = mask)\n",
    "\n",
    "    # Paste the forward image on the background image\n",
    "  #  img1_bg2 = cv2.cvtColor(imgrot,cv2.COLOR_GRAY2GBGR)\n",
    "    imgpaste = cv2.add(img1_bg,img2_fg)\n",
    "\n",
    "    return imgpaste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メイン関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "aruco = cv2.aruco\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "img=cv2.imread(\"img/\"+str(name)+\".jpg\")\n",
    "imgback = cv2.imread(\"img/\"+str(name)+\".jpg\")\n",
    "\n",
    "img_paths = Path(\"img/deformation/scalling_diff_BGR\") / \"%04d.png\"\n",
    "\n",
    "height,width,color=imgback.shape\n",
    "\n",
    "angle=0\n",
    "scale=0.2\n",
    "\n",
    "ar4=cv2.imread(\"ARUCO/BGR2GRAY_ar04.png\")\n",
    "ar5=cv2.imread(\"ARUCO/BGR2GRAY_ar05.png\")\n",
    "ar6=cv2.imread(\"ARUCO/BGR2GRAY_ar06.png\")\n",
    "ar7=cv2.imread(\"ARUCO/BGR2GRAY_ar07.png\")\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap2 = cv2.VideoCapture(str(img_paths))\n",
    "\n",
    "rt_pts=np.zeros((8,4,2),dtype = np.float32)\n",
    "rt_bord_pts=np.zeros((16,2),dtype = np.float32)\n",
    "rt_pro_pts=np.zeros((16,2),dtype = np.float32)\n",
    "\n",
    "count=[0,1,2,3]\n",
    "count2=[0,1,2,3,4,5,6,7]\n",
    "count3=[4,5,6,7]\n",
    "\n",
    "mat1, mask1 = cv2.findHomography(def_pro_pts, def_pro_pts, cv2.RANSAC,1)#初期設定（変更なし）\n",
    "mat2, mask2 = cv2.findHomography(def_bord_pts, def_bord_pts, cv2.RANSAC,1)\n",
    "frag=1#待機時間管理\n",
    "\n",
    "while(True):\n",
    "\n",
    "    t0 = time.time() #時間計測開始   \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    ret_img, frame_img = cap2.read()\n",
    "    \n",
    "    if ret_img==True:\n",
    "\n",
    "    # Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "        frame2=cv2.warpPerspective(frame_img, mat2, (3*width, 3*height))\n",
    "        frame3=cv2.warpPerspective(frame2, mat1, (width, height))#カメラから見たプロジェクタ上の座標→カメラから見たボード上の座標\n",
    "    \n",
    "\n",
    "        imgpaste = cvpaste(ar4, frame3, 0, -90, angle, scale)#AR貼り付け\n",
    "        imgpaste2 = cvpaste(ar5, imgpaste, 180, 0, angle, scale)\n",
    "        imgpaste3 = cvpaste(ar6, imgpaste2, 0, 90, angle, scale)\n",
    "        imgpaste4 = cvpaste(ar7, imgpaste3, -180, 0, angle, scale)\n",
    "\n",
    "    \n",
    "\n",
    "        cv2.namedWindow('screen', cv2.WINDOW_NORMAL)\n",
    "        cv2.setWindowProperty('screen', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "        cv2.imshow('screen',imgpaste4)\n",
    "  \n",
    "    else:\n",
    "        cap2.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    new_corners, new_ids, rejectedImgPoints = aruco.detectMarkers(frame, dictionary)\n",
    "    \n",
    "    if not new_corners:\n",
    "        pass\n",
    "    \n",
    "#    elif new_ids.size<=4:\n",
    " #       pass\n",
    "        \n",
    "    else:\n",
    "        #rt_pts=np.zeros((8,4,2),dtype = np.float32)\n",
    "        for i in count:\n",
    "            for j in count:\n",
    "                    rt_pts[i+4][j][0]=0\n",
    "                    rt_pts[i+4][j][1]=0\n",
    "            \n",
    "        rt_bord_pts=np.zeros((16,2),dtype = np.float32)#reset\n",
    "        rt_pro_pts=np.zeros((16,2),dtype = np.float32)\n",
    "        def_bord_pts2=np.zeros((16,2),dtype = np.float32)\n",
    "        def_pro_pts2=np.zeros((16,2),dtype = np.float32)\n",
    "        num=new_ids.size-1\n",
    "        \n",
    "        for i in count2:\n",
    "            for j in count2:\n",
    "                if j ==new_ids[i][0]:\n",
    "                    for h in count:\n",
    "                        rt_pts[j][h][0]=new_corners[i][0][h][0]                           \n",
    "                        rt_pts[j][h][1]=new_corners[i][0][h][1]\n",
    "            if num==i:\n",
    "                   break\n",
    "            \n",
    "\n",
    "        k=0\n",
    "        for i in count:\n",
    "            if rt_pts[i][0][0]==rt_pts[i][0][1]==0:\n",
    "                for j in count:\n",
    "                    def_bord_pts2=np.delete(def_bord_pts2,-1,0)\n",
    "                    rt_bord_pts=np.delete(rt_bord_pts,-1,0)\n",
    "\n",
    "                    \n",
    "            else:\n",
    "                for j in count:\n",
    "                    def_bord_pts2[4*k+j][0]=def_bord_pts[4*i+j][0]\n",
    "                    def_bord_pts2[4*k+j][1]=def_bord_pts[4*i+j][1] \n",
    "                    rt_bord_pts[4*k+j][0]=rt_pts[i][j][0]\n",
    "                    rt_bord_pts[4*k+j][1]=rt_pts[i][j][1] \n",
    "\n",
    "                k=k+1\n",
    "                        \n",
    "        k=0\n",
    "       # print(rt_pts)\n",
    "        for i in count:\n",
    "            if rt_pts[i+4][0][0]==rt_pts[i+4][0][1]==0:\n",
    "                for j in count:\n",
    "                    def_pro_pts2=np.delete(def_pro_pts2,-1,0)\n",
    "                    rt_pro_pts=np.delete(rt_pro_pts,-1,0)\n",
    "                  #  print(\"deleted\")\n",
    "                    \n",
    "            else:\n",
    "                for j in count:\n",
    "                    def_pro_pts2[4*k+j][0]=def_pro_pts[4*i+j][0]\n",
    "                    def_pro_pts2[4*k+j][1]=def_pro_pts[4*i+j][1]\n",
    "                    rt_pro_pts[4*k+j][0]=rt_pts[i+4][j][0]\n",
    "                    rt_pro_pts[4*k+j][1]=rt_pts[i+4][j][1]\n",
    "                k=k+1\n",
    "        if  rt_pro_pts.size==0 or rt_bord_pts.size==0 : \n",
    "            pass\n",
    "            \n",
    "        elif frag>=30:#待機時間管理\n",
    "            mat1, mask1 = cv2.findHomography(rt_pro_pts, def_pro_pts2, cv2.RANSAC,1)\n",
    "            mat2, mask2 = cv2.findHomography(def_bord_pts2, rt_bord_pts, cv2.RANSAC,1)\n",
    "    #print(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) &0xFF == ord('q'):\n",
    "        break\n",
    "    frag=frag+1\n",
    "    t1 = time.time()                # 計測終了時間\n",
    "    elapsed_time = float(t1 - t0)   # 経過時間\n",
    "   # print(elapsed_time)             # 経過時間を表示\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap2.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "差分画像生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "img = cv2.imread(\"img/\"+str(name)+\".jpg\") \n",
    "h,w,color=img.shape\n",
    "\n",
    "n=0\n",
    "i=0\n",
    "t=1/w\n",
    "\n",
    "while True:\n",
    "    pts1 = np.float32([[0,0],[w,0],[0,h]])\n",
    "    pts2 = np.float32([[0-w*t,0-h*t],[w+w*t,0-h*t],[0-w*t,h+h*t]])\n",
    "\n",
    "    mat = cv2.getAffineTransform(pts1,pts2)\n",
    "    transed_img = cv2.warpAffine(img, mat, (w, h))\n",
    "    cv2.imwrite(\"./img/deformation/scalling/\" + str(i) + \".png\", transed_img)\n",
    "\n",
    "    n+=1\n",
    "    t+=1/w\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    if n==2:#秒数によって変える\n",
    "        break    \n",
    "\n",
    "while True:\n",
    "    pts1 = np.float32([[0,0],[w,0],[0,h]])\n",
    "    pts2 = np.float32([[0-w*t,0-h*t],[w+w*t,0-h*t],[0-w*t,h+h*t]])\n",
    "\n",
    "    mat = cv2.getAffineTransform(pts1,pts2)\n",
    "    transed_img = cv2.warpAffine(img, mat, (w, h))\n",
    "    cv2.imwrite(\"./img/deformation/scalling/\" + str(i) + \".png\", transed_img)\n",
    "\n",
    "    n+=1\n",
    "    t=t-1/w\n",
    "    i+=1\n",
    "\n",
    "    if n==5:#秒数によって変える\n",
    "        break\n",
    "    \n",
    "t=t-1/h\n",
    "        \n",
    "while True:\n",
    "    pts1 = np.float32([[0,0],[w,0],[0,h]])\n",
    "    pts2 = np.float32([[0-w*t,0-h*t],[w+w*t,0-h*t],[0-w*t,h+h*t]])\n",
    "\n",
    "    mat = cv2.getAffineTransform(pts1,pts2)\n",
    "    transed_img = cv2.warpAffine(img, mat, (w, h))\n",
    "\n",
    "    cv2.imwrite(\"./img/deformation/scalling/\" + str(i) + \".png\", transed_img)\n",
    "    n+=1\n",
    "    t=t-1/w\n",
    "    i+=1\n",
    "    if n==7:#秒数によって変える\n",
    "        break\n",
    "    \n",
    "while True: \n",
    "    pts1 = np.float32([[0,0],[w,0],[0,h]])\n",
    "    pts2 = np.float32([[0-w*t,0-h*t],[w+w*t,0-h*t],[0-w*t,h+h*t]])\n",
    "\n",
    "    mat = cv2.getAffineTransform(pts1,pts2)\n",
    "    transed_img = cv2.warpAffine(img, mat, (w, h))\n",
    "    cv2.imwrite(\"./img/deformation/scalling/\" + str(i) + \".png\", transed_img)\n",
    "    n+=1\n",
    "    t+=1/w\n",
    "    i+=1\n",
    "    if n==10:#秒数によって変える\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "n=0\n",
    "i=0\n",
    "\n",
    "or_img=cv2.imread(\"img/\"+str(name)+\".jpg\")\n",
    "or_img_gray=cv2.cvtColor(or_img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "h,w,color=or_img.shape\n",
    "\n",
    "\n",
    "\n",
    "while(True):\n",
    "    i='%04d'% n  \n",
    "    img=cv2.imread(\"./img/deformation/scalling/\" + str(n) + \".png\")\n",
    "    img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    im_diff_gray=or_img_gray.astype(int)-img_gray.astype(int)\n",
    "    im_diff_center=np.floor_divide(im_diff_gray, 2) + 128\n",
    "    im_diff_abs=np.abs(im_diff_center)\n",
    "    img_white = np.ones((h,w),np.uint8)\n",
    "    for k in range(h):\n",
    "        for j in range(w):\n",
    "            img_white[k][j]=float(im_diff_abs[k][j])\n",
    "            \n",
    "    im_diff=cv2.cvtColor(img_white,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    path = \"./img/deformation/scalling_diff_BGR/\" + str(i) + \".png\"\n",
    "    \n",
    "    cv2.imwrite(path, im_diff) # ファイル保存\n",
    "    n+=1\n",
    "    if n==10:#秒数によって変える\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(im_diff_abs[24][23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 400, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_opencv)",
   "language": "python",
   "name": "conda_opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
